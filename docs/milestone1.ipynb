{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD20 Milestone 1\n",
    "Group 20: Lindsey Brown, Xinyue Wang, Kevin Yoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "**1. Introduction**\n",
    "\n",
    "    1.1 Automatic Differentiation as a Solution to the Problem of Computing Derivatives\n",
    "    1.2 Application of AD Techniques\n",
    "    \n",
    "**2. Background**\n",
    "\n",
    "    2.1 Chain Rule\n",
    "    2.2 Computational Graph Structure\n",
    "    2.3 Dual Numbers\n",
    "    2.4 Elementary Functions\n",
    "    \n",
    "**3. Package Usage**\n",
    "\n",
    "    3.1 User Interaction\n",
    "    3.2 Importing AD20\n",
    "    3.3 Instantiating AD20 Objects\n",
    "    \n",
    "**4. Software Organization**\n",
    "\n",
    "    4.1 Directory Structure\n",
    "    4.2 Modules and Functionality\n",
    "    4.3 Testing and Coverage\n",
    "    4.4 Package Distribution\n",
    "    \n",
    "**5. Implementation**\n",
    "\n",
    "    5.1 Core Data Structures\n",
    "    5.2 Classes\n",
    "    5.3 Class Methods and Attributes\n",
    "    5.4 External Dependencies\n",
    "    5.5 Elementary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "The AD20 package performs the forward mode of automatic differentiation of user defined functions, evaluating both the function and its derivatives to machine precision.\n",
    "\n",
    "## 1.1 Automatic Differentiation as a Solution to the Problem of Computing Derivatives\n",
    "\n",
    "Differentiation is a fundamental operation for computational science. Used in a variety of applications from optimization to sensitivity analysis, differentiation is most useful when two conditions are met: it must be exact (up to machine precision) and computationally efficient.\n",
    "\n",
    "Automatic differentiation (AD) (i.e. algorithmic differentiation, computational differentiation) computes the derivative of a function, unique for its ability to handle complex combinations of functions without sacrificing the accuracy. Regardless of how complex the function may be, AD takes advantage of the fact that the function can be decomposed to a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). \n",
    "\n",
    "Through computing the derivatives of these basic elementary functions and repeatedly applying the chain rule, AD meets the two aforementioned conditions and distinguishes itself from other modes of differentiation, namely numerical differentiation and symbolic differentiation. \n",
    "\n",
    "- While numerical differentiation may be easy to implement and can flexibly handle any types of functions, accuracy is sacrificed due to truncation and rounding errors - numerical differentiation serves more as an estimation technique based on small inputs. Unlike numerical differentiation, automatic differentiation does not rely on approximating the derivative through the choice of a small perturbation in the input, and instead computes derivatives exactly to machine precision, thus avoiding these accuracy and stability problems.\n",
    "\n",
    "\n",
    "- While symbolic differentiation may ensure accuracy up to machine precision, computational efficiency is sacrified due to its nature of building complex expression trees. For complex functions, these expression trees can quickly become very large with mathematical expressions. Unlike symbolic differentiation, automatic differentiation views functions as compositions of basic operations, remains accurate up to machine precision, and maintains computational efficiency since it does not require the buildup and evaluation of complex expression trees.\n",
    " \n",
    "Thus, it is clear that automatic differentiation has advantages over other commonly used techniques for computing derivatives. These advantages make the use of AD attractive to many scientific applications. \n",
    "\n",
    "## 1.2 Application of AD Techniques\n",
    "\n",
    "Through its improved accuracy and efficiency, AD has many different applications where accuracy, precision, and efficiency is crucial in computation. Some include \n",
    "\n",
    "- Machine learning (ability to understand data and make models/predictions)\n",
    "- Parameter optimization (ability to choose best parameter values under given conditions)\n",
    "- Sensitivity analysis (ability to understand different factors and their impact)\n",
    "- Physical modeling (ability to visualize and depict data through models)\n",
    "- Probabilistic inference (i.e. Hamiltonian Monte Carlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Background\n",
    "\n",
    "## 2.1 Chain Rule\n",
    "\n",
    "Chain rule lies at the heart of AD as it decomposes complex combinations of functions into simpler, more elementary functions then computing the derivatives of the elementary functions to piece them together to get the overall derivative. By expressing the function as a composition of elementary functions and operations, derivative of the function can be calculated.\n",
    "\n",
    "Suppose we have a function $f\\left(g\\left(t\\right)\\right)$ and we want the derivative of $f$ with respect to $t$.  The derivative is $$\\dfrac{\\partial f}{\\partial t} = \\dfrac{\\partial f}{\\partial g}\\dfrac{\\partial g}{\\partial t}.$$\n",
    "\n",
    "## 2.2 Graph Structure on Calculations\n",
    "\n",
    "### The Computational Graph\n",
    "Consider the example function $$f\\left(x,y\\right) = x^{3} + \\sin(5y)$$\n",
    "\n",
    " The evaluation trace looks like:\n",
    "\n",
    "| Trace | Elementary Function |  Elementary Function Derivative | $\\nabla_{x}$ Value  | $\\nabla_{y}$ Value  | \n",
    "| :---: | :-----------------: | :-----------: | :-------------: | :----------------------: | :---------------------: | \n",
    "| $x_{1}$ | $x_{1}$ |$\\dot{x_{1}}$|$1$|$0$|\n",
    "| $x_{2}$ | $x_{2}$ |$\\dot{x_{2}}$|$0$|$1$|\n",
    "| $x_{3}$ | $x_{1}^3$ |$3x_{1}^2\\dot{x_{1}}$|$3x^3$|$0$|\n",
    "| $x_{4}$ | $5x_{2}$ |$5\\dot{x_{2}}$|$0$|$5$|\n",
    "| $x_{5}$ | $\\sin{x_{4}}$ |$\\cos{x_{4}}\\dot{x_{4}}$|$0$|$5\\cos{5y}$|\n",
    "| $x_{6}$ | $x_{3}+x_{5}$ | $\\dot{x_{3}}+\\dot{x_{5}}$ |$3x^2$|$5\\cos{5y}$|\n",
    "\n",
    "Then, in the end, the derivative of $f$, call it $f'$, comes out to be $$f' = 3x^2 + 5\\cos(5y)$$\n",
    "\n",
    "One way to visualize what is going on is to represent the evaluation trace with a graph.\n",
    "\n",
    "![comp-graph](figs/graph.jpg)\n",
    "\n",
    "\n",
    "## 2.3 Dual Numbers\n",
    "A dual number has a real part and a dual part.  We write $$f = y + \\epsilon y^{\\prime}$$ and refer to $y^{\\prime}$ as the dual part.  We *define* the number $\\epsilon$ so that $\\epsilon^{2} = 0$.  **This does not mean that $\\epsilon$ is zero!**  $\\epsilon$ is not a real number.\n",
    "\n",
    "#### Some properties of dual numbers:\n",
    "* Conjugate:  $f^{*} = y - \\epsilon y^{\\prime}$.\n",
    "* Magnitude: $\\left|f\\right|^{2} = ff^{*} = \\left(y+\\epsilon y^{\\prime}\\right)\\left(y-\\epsilon y^{\\prime}\\right) = y^{2}$.\n",
    "* Polar form: $f = y\\left(1 + \\dfrac{y^{\\prime}}{y}\\right)$.\n",
    "\n",
    "### Example (from lecture)\n",
    "Recall that the derivative of $f=z^{2}$ is $f^{\\prime} = 2zz^{\\prime} = 2z$.\n",
    "\n",
    "Now if we extend $z$ so that it has a real part and a dual part ($z\\leftarrow z + \\epsilon z^{\\prime}$) and evaluate $f$ we have\n",
    "\\begin{align}\n",
    "  f &= \\left(z + \\epsilon z^{\\prime}\\right)^{2} \\\\\n",
    "    &= z^{2} + 2zz^{\\prime}\\epsilon + \\underbrace{z^{\\prime^{2}}\\epsilon^{2}}_{=0} \\\\\n",
    "    &= z^{2} + 2zz^{\\prime}\\epsilon.\n",
    "\\end{align}\n",
    "\n",
    "## 2.4 Elementary Functions\n",
    "Any complex equation can be broken into combinations of the elementary functions. Some of those include the elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, tan, sqrt etc.). We will not go into details about how to calculate the derivatives of those functions here, but more information can be found on the following link.\n",
    "\n",
    "http://www.nabla.hr/FU-DerivativeA5.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Package Usage\n",
    "\n",
    "## 3.1 User Interaction\n",
    "Users should use ADnum objects to wrap up all mathematical meaning values and formulas. All operations are processed as an ADnum object. Users need to create an ADnum object for each input variable and use all the mathematical functions defined in the ADmath library to implement special functions.\n",
    "\n",
    "## 3.2 Importing AD20\n",
    "\timport AD20\n",
    "or \n",
    "\n",
    "\tfrom AD20 import ADnum\n",
    "    \n",
    "\tfrom AD20 import ADmath\n",
    "    \n",
    "\tfrom AD20 import ADgraph\n",
    "\n",
    "\n",
    "## 3.3 Instantiating AD20\n",
    "\tfrom AD20 import ADnum\n",
    "\tfrom AD20 import ADmath\n",
    "\ta = ADnum(2)\n",
    "\tb = ADmath.sin(a)\n",
    "\t\n",
    "Both a and b are ADnum objects, which have the attributes described in the class implementation below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Software Organization\n",
    "We would like to let the user use all numerical operations defined in our AD20 package. Within AD20 package, there is ADnum module, ADmath module  and ADgraph module\n",
    "\n",
    "For either a scalar or vector input (either as a numpy array or a list), we will convert the input into an ADnum object, which can interact with the other modules. ADnum will also contain an overloaded version of basic operations, including addition, subtraction, multiplication, division, and exponentiation, so that the value and derivative are correctly updated.\n",
    "\n",
    "For special functions, we will use ADmath to compute the numerical values and the corresponding derivatives. In particular, ADmath will contain functions abs, exp, log, sin, cos, and tan.\n",
    "\n",
    "To show a calculation graph, we use ADgraph (and ADtable) to show the forward mode calculation process.\n",
    "\n",
    "###  4.1 Directory Structure\n",
    "    AD20/\n",
    "        AD20/\n",
    "            __init__.py\n",
    "                ADnum/\n",
    "                    __init__.py\n",
    "                    ADnum.py\n",
    "                ADmath/\n",
    "                    __init__.py\n",
    "                    ADmath.py\n",
    "                ADgraph/\n",
    "                    __init__.py\n",
    "                    ADgraph.py\n",
    "                    ADtable.py\n",
    "        Tests/\n",
    "            __init__.py\n",
    "            test_AD20.py\n",
    "    README.md\n",
    "    setup.py\n",
    "    LICENSE\n",
    "\n",
    "###  4.2 Modules and Functionality\n",
    "ADnum: wrap numbers or tuples as a AD object. Moreover, do all of the numerical operations and keep track of all derivatives\n",
    "ADmath: assign special math meanings and functions to ADnum’s and keep track of the derivatives\n",
    "ADgraph: trace the calculation process and generate table or graph\n",
    "\n",
    "In particular, these modules contain the following:\n",
    "ADnum.py contains the class for ADnum.  This class is fully described below.  It takes as input a single scalar input or a vector input (as either a numpy array or list) and outputs an ADnum object.  Within this class, we will overload basic operations as outlined below.\n",
    "\n",
    "###  4.3 Testing and Coverage\n",
    "The tests will be stored in the tests directory (see the repo structure above).  We will use pytest to perform our testing, using TravisCI and Coveralls for continuous integration and verifying code coverage respectively.\n",
    "\n",
    "###  4.4 Package Distribution\n",
    "We will use PIP in PyPi to distribute our package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Implementation\n",
    "Automatic differentiation will be implemented through the use of ADnum objects and building the functions for which we want to take derivatives from these ADnum objects as well as the special functions defined for ADnum objects in the ADmath module.  Each of these functions is itself an ADnum object so has an associated value and derivative which was updated when constructing the ADnum object through basic operations and special functions.\n",
    "\n",
    "### 5.1 Core Data Structures\n",
    "The main data structure used to represent the functions on which we are performing automatic differentiation will be tuples, with the first entry the value of the ADnum object and the second entry its derivative.  In the case of scalar input, the derivative is also a float.  For vector valued input, the derivative is the gradient of the function, stored as a numpy array.\n",
    "In order to build and store computational graphs, we will use a dictionary as the computational graph, where the keys are the nodes of the graph, stored as ADnum objects, and the values associated with each key are the children of that node, stored as lists of ADnum objects.\n",
    "\n",
    "### 5.2 Implemented Classes\n",
    "The main class will be implemented in the ADnum module, which will create ADnum objects.  The ADnum objects will store the current value of the function and its derivative as attributes.  By combining simple ADnum objects with basic operations and simple functions, we can construct any function we like.  For example,\n",
    "\n",
    "    X = AD20.ADnum(4)\n",
    "    Y = AD20.ADnum(0)\n",
    "    F = X+ADmath.sin(Y)\n",
    "    \n",
    "Where F is now an ADnum object, and ADmath.sin() is a specially defined sine function which takes as input an ADnum object and returns an ADnum object, which allows us to evaluate F and its derivative,\n",
    "\n",
    "    F.val = 4\n",
    "    F.deriv = [1, 1] \n",
    "    X.val = 4\n",
    "    X.deriv = 1\n",
    "\n",
    "In addition to the sine function, the ADmath module will also implement the other trigonometric functions, the natural exponential, and the natural logarithm.\n",
    "\n",
    "We will also implement a class, ADgraph, for computational graphs.  The constructor takes as input a dictionary, as described above where the keys are nodes and values are the children of the key node. \tThis can then be used to perform forward propagation and could be extended later to include back propagation as an extension of our project.\n",
    " \n",
    "### 5.3 Class Methods and Attributes\n",
    "Each ADnum object will have two attributes for the two major functions desired of the class.  The val attribute will be the ADnum object evaluated at the given value and the der attribute will be its derivative.  In addition, each ADnum object will have a graph attribute, which stores the dictionary which can be used to build a computational graph in the ADgraph class.  The ADnum class will also include methods to overload basic operations, __add__(), __radd__(), __mul__(), __rmul__(), __sub__(), __truedivide__(), and __pow__().  The result of overloading is that the adding, subtracting, multiplying, dividing, or exponentiating two ADnum objects returns an ADnum object as well as addition or multiplication by a constant.  For example, Y1, Y2, and Y3 would all be recognized as ADnum objects:\n",
    "\n",
    "    X1= ADnum(7)\n",
    "    X2 = ADnum(15)\n",
    "    Y1 = X1+X2\n",
    "    Y2 = X1*X2+X1\n",
    "    Y3 = 5*X1+X2+100\n",
    "\n",
    "The resulting ADnum objects have both a value and derivative.\n",
    "\n",
    "The ADgraph class will be constructed from a dictionary, stored in the attribute dict.  This class will also have an attribute inputs, which stores the nodes which have no parents.  This class will implement a deriv method which returns the derivative from the computational graph.\n",
    "\n",
    "### 5.4 External Dependencies\n",
    "In order to implement the elementary functions, our class will rely on numpy’s implementation of the trigonometric functions, exponential functions, and natural logarithms for evaluation of these special functions.\n",
    "\n",
    "We will also use numpy to implement matrix and vector multiplication in cases where the function is either vector valued or takes a vector as an input.\n",
    "\n",
    "### 5.5 Elementary Functions\n",
    "As outlined above, we will have a special ADmath module which defines the trigonometric, exponential, and logarithmic functions to be used on ADnum objects, so that they both take as input and return an ADnum object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
